{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport yfinance as yf\nimport datetime\n    \n# using now() to get current time\ncurrent_time = datetime.datetime.now()\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-02-18T12:25:08.560940Z","iopub.execute_input":"2025-02-18T12:25:08.561307Z","iopub.status.idle":"2025-02-18T12:25:09.222820Z","shell.execute_reply.started":"2025-02-18T12:25:08.561270Z","shell.execute_reply":"2025-02-18T12:25:09.221765Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#fist step is to load the data from yfinance api \n\ndef load_data(ticker,start_date='2020-01-01',end_date=current_time):\n    '''\n    parameters \n    ticker=stock ticker symbol \n    start_date= date from when to import\n    end_date=date till when to import\n    '''\n    stock_data=yf.download(ticker,start=start_date,end=end_date)\n    return stock_data\n\nstock_data=load_data('AAPL','2020-01-01','2025-02-01')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T12:25:09.223819Z","iopub.execute_input":"2025-02-18T12:25:09.224300Z","iopub.status.idle":"2025-02-18T12:25:09.567036Z","shell.execute_reply.started":"2025-02-18T12:25:09.224269Z","shell.execute_reply":"2025-02-18T12:25:09.565933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now to split the date into training and validation sets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\ndef preprocess_data(stock_data,target_column='Close',test_size=0.2):\n    #separate it into features and labels\n    X=stock_data.drop([target_column,'Adj Close'], axis=1) #features\n    y=stock_data[target_column] #label\n    #perform the train valid split\n    X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=test_size,random_state=0)\n    return X_train, X_valid, y_train, y_valid\n\nX_train, X_valid, y_train, y_valid = preprocess_data(stock_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T12:25:09.569370Z","iopub.execute_input":"2025-02-18T12:25:09.569768Z","iopub.status.idle":"2025-02-18T12:25:10.227339Z","shell.execute_reply.started":"2025-02-18T12:25:09.569728Z","shell.execute_reply":"2025-02-18T12:25:10.226270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n#now lets define the model\ndef build_model(dropout_ratio,act_func):\n#define layers with unit and their activation function,\n#add dropout ratio to prevent overfitting\n    model= keras.Sequential([\n    layers.BatchNormalization(),\n    layers.Dense(1024, activation=act_func),\n    layers.Dropout(dropout_ratio),\n    layers.BatchNormalization(),\n    layers.Dense(512, activation=act_func),\n    layers.Dropout(dropout_ratio),\n    layers.BatchNormalization(),\n    layers.Dense(256, activation=act_func),\n    layers.Dropout(dropout_ratio),\n    layers.BatchNormalization(),    \n    layers.Dense(1,activation='linear')\n    ])\n##select the type of loss and optimizer\n    model.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n    loss='mse',\n    metrics=['mean_absolute_error']\n    )\n    return model\n\nmodel=build_model(0.3,'relu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T12:45:34.236851Z","iopub.execute_input":"2025-02-18T12:45:34.237227Z","iopub.status.idle":"2025-02-18T12:45:34.266810Z","shell.execute_reply.started":"2025-02-18T12:45:34.237196Z","shell.execute_reply":"2025-02-18T12:45:34.265770Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now to compile and fit the model","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\n#fit the model for training\ndef train_model(model,X_train, y_train, X_valid, y_valid,epochs=50, batch_size=32):\n    history=model.fit(\n        x=X_train,\n        y= y_train,\n        batch_size=batch_size,\n        epochs=epochs,\n        verbose=\"auto\",\n        validation_data=(X_valid,y_valid),\n    )\n    return history\n\nhistory = train_model(model, X_train, y_train, X_valid, y_valid)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now to plot the loss land val_loss graphs with accuracy graphs ","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef plot_training_history(history):\n    \"\"\"\n    Plots the training history for loss and accuracy.\n    \n    Parameters:\n    history: Training history from model training.\n    \"\"\"\n    # Plot loss\n    plt.plot(history.history['loss'], label='train_mse')\n    plt.plot(history.history['val_loss'], label='val_mse')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('MSE')\n    plt.legend()\n    plt.show()\n\n    # Plot mean squared error (accuracy)\n    plt.plot(history.history['mean_absolute_error'], label='train_mae')\n    plt.plot(history.history['val_mean_absolute_error'], label='val_mae')\n    plt.title('Model Mean Squared Error')\n    plt.xlabel('Epoch')\n    plt.ylabel('MAE')\n    plt.legend()\n    plt.show()\n\nplot=plot_training_history(history)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now to predict and check the model using test data ","metadata":{}},{"cell_type":"code","source":"\ndef evaluate_model(model, X_test, y_test,current_time):\n    \"\"\"\n    Parameters:\n    model: Keras model.\n    X_test (ndarray): Test features.\n    y_test (ndarray): Test labels.\n    \"\"\"\n    # import test data\n    ticker = \"AAPL\"\n    stock_test = yf.download(ticker, start='2025-02-01', end=current_time)\n    X_test=stock_test.drop(['Close','Adj Close'],axis=1)\n    y_test=stock_test['Close']\n    # Evaluate the model on the test data\n    test_mse, test_mae = model.evaluate(X_test, y_test)\n    \n    print(f\"Test Mean Squared Error:\",round(test_mse,2))\n    print(f\"Test Loss:\",round(test_mae,2))\n    return round(test_mse,2), round(test_mae,2)\n\ntest_loss, test_mse = evaluate_model(model, X_test, y_test,current_time)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}